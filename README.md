# Scrutiny

This is a collection of tools for scrutinising the results of articles and preprints. 



[TOC]



## Included tools



### Statcheck

#### Webapp

[statcheck.io](https://statcheck.io)

#### R package

[statcheck](https://cran.r-project.org/web/packages/statcheck/)

#### References

Nuijten, M. B., & Polanin, J. R. (2020) “statcheck”: Automatically detect statistical reporting inconsistencies to increase reproducibility of meta-analyses. *Research Synthesis Methods.* https://doi.org/10.1002/jrsm.1408 [pdf on ilias]

Nuijten, M. B., Hartgerink, C. H., Van Assen, M. A., Epskamp, S., & Wicherts, J. M. (2016). The prevalence of statistical reporting errors in psychology (1985–2013). *Behavior Research Methods, 48,* 1205-1226. https://doi.org/10.3758/s13428-015-0664-2 



### GRIM & GRIMMER

#### Webapp

GRIM (means) http://www.prepubmed.org/general_grim/

GRIMMER (SDs, SEs, or variance) http://www.prepubmed.org/grimmer/ 

#### R package

[scrutiny](https://cran.r-project.org/web/packages/scrutiny)

#### References

Brown, Nicholas J. L., Heathers, James A. J. (2016). The GRIM Test: A Simple Technique Detects Numerous Anomalies in the Reporting of Results in Psychology. *Social Psychological and Personality Science. 8*(4), pp 363–369. https://doi.org/10.1177/1948550616673876 

Heathers, J. (2016) The GRIM test — a method for evaluating published research. https://jamesheathers.medium.com/the-grim-test-a-method-for-evaluating-published-research-9a4e5f05e870 

Anaya J. (2016) The GRIMMER test: A method for testing the validity of reported measures of variability. https://doi.org/10.7287/peerj.preprints.2400v1 



### SPRITE

#### **Webapp** 

https://steamtraen.shinyapps.io/rsprite/ 

#### R package

[rsprite2](https://cran.r-project.org/web/packages/rsprite2)

#### References

Heathers, J. A., Anaya, J., van der Zee, T., Brown, N. J. L. (2018). Recovering data from summary statistics: Sample Parameter Reconstruction via Iterative TEchniques (SPRITE). PeerJ. https://doi.org/10.7287/peerj.preprints.26968v1



## Tools to be added

### *p*-curve

#### Webapp

https://www.p-curve.com/app4/ 

#### R package

[dmetar](https://dmetar.protectlab.org/) (see also Harrer chapter below).

#### References

Simonsohn, Nelson, & Simmons (2014) p-Curve: A Key to the File-Drawer. *Journal of Experimental Psychology: General.* https://doi.org/10.1037/a0033242 

Simonsohn, Nelson, & Simmons (2015) Better p-curves: Making p-curve analysis more robust to errors, fraud, and ambitious p-hacking, a Reply to Ulrich and Miller (2015). *Journal of Experimental Psychology: General.* https://doi.org/10.1037/xge0000104 

Harrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D. (2021). Doing Meta-Analysis with R: A Hands-On Guide. Boca Raton, FL and London: Chapman & Hall/CRC Press. ISBN 978-0-367-61007-4. https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pub-bias.html#p-curve 

Erdfelder & Heck (2019) Detecting Evidential Value and p-Hacking With the p-Curve Tool: A Word of Caution. https://doi.org/10.1027/2151-2604/a000383 



### *Z*-curve

#### Webapp

[to be added]

#### R package

[to be added]







